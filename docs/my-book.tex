% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\title{The Ethical Dilemma of Producing Artificial Intelligence (AI)}
\author{Zach Gooding, Nisarg Jhaveri, Catherine Visscher, William Yu, Aaron Zhao}
\date{08-16-2023}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={The Ethical Dilemma of Producing Artificial Intelligence (AI)},
  pdfauthor={Zach Gooding, Nisarg Jhaveri, Catherine Visscher, William Yu, Aaron Zhao},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This website is a learning tool for the Ross community, including students, alumni, faculty, and staff, on the ethical issues of how we produce and generate artificial intelligence. The information book will first begin with team introductions then discuss a general introduction into the current production/generation of artificial intelligence.

After these introductions, we will transition into the main section of the book, discussing several areas of ethical concern as it relates to As artificial intelligence (AI) continues its integration into various facets of society, it becomes imperative to critically assess the ethical implications surrounding its development and usage. This website serves as a learning tool for the Ross community to explore key ethical considerations in the AI landscape, with a focus on large language models.

Before jumping into content, we will introduce the team that put this resource together for your education purposes.

At its core, this resource aims to unpack pressing ethical issues in AI advancement. We will begin by analyzing the substantial infrastructure and resources needed to create increasingly complex AI models and assessing environmental and financial costs. Moving forward, we will discuss crucial data-related factors, including unauthorized scraping and ingrained biases.
Additionally, this website will address inherent challenges in training ethical, safe AI systems. It will also stress the importance of responsible data handling and privacy measures taken by AI companies. Risks of misalignment between AI and human values will similarly be explored.

To conclude, we will overview two domains - personalized AI and open-source projects - that underscore AI's societal benefits despite its problems. Overall, we hope to spur thoughtful discussion about establishing ethical frameworks to guide AI progress in a way that prioritizes privacy, ensures security, and promotes human-centric values. This introduction sets the stage for an examination of AI ethics tailored to the Ross community.

\hypertarget{about-us}{%
\chapter{About Us}\label{about-us}}

Hi there, we are the Insight Titans! We are part of the Masters of Business Analytics Cohort Class of 2024. We are excited to share some helpful information with you that we hope you find useful for learning, just as we did in creating this resource.

\hypertarget{zach-gooding}{%
\section{Zach Gooding}\label{zach-gooding}}

Hello everyone! My name is Zach Gooding, and I am originally from Westmont, Illinois, a Western Suburb of Chicago. I graduated from Augustana College in the Spring of 2023 with majors in Data Analytics and Business Administration with concentrations in Marketing, Management, and MIS. I was also a four year member of the Varsity Baseball team at Augustana and was a part of back to back Conference Championship teams. My undergraduate experience made me realize I was just beginning to scratch the surface in the field of Data Analytics, so I am thrilled to be taking classes at Michigan Ross to further my education.

My prior work experience is as a Marketing and Data Analytics Intern for the NTT INDYCAR Series and Canes Baseball in their Illinois Division. In my free time, you can find me watching the Cubs game, listening to a lot of music, and experiencing everything Ann Arbor has to offer. I hope you find our information useful on Large Language Models as we enter this new age of Data.

\hypertarget{nisarg-jhaveri}{%
\section{Nisarg Jhaveri}\label{nisarg-jhaveri}}

Hey-o! I am Nisarg Jhaveri, an enthusiast from Boston, MA, and an auditor by profession. I completed my undergrad at the University of Massachusetts Lowell in Finance and Accounting with a minor in Psychology. I did five internships during that time frame to explore different industries. I graduated back in 2022, after which I worked at EY for a year with their Wealth and Asset Management team, but I kept itching to go back to school to learn more about programming, a topic that I couldn't fully explore.
I decided to join the Ross School of Business because of this and hope to make the most out of it to truly leverage data and create value while working on a few personal projects.
P.S. I am a very social person so feel free to reach out, I would love to chat/help :)

\hypertarget{catherine-visscher}{%
\section{Catherine Visscher}\label{catherine-visscher}}

Hello! I am Catherine Visscher, a Michigan native from Livonia, Michigan. I graduated from the University of Michigan College of Engineering Winter 2023 with a B.S.E in Chemical Engineering and am currently a Master's of Business Analytics student at the Stephen M. Ross School of Business. One thing my undergraduate degree has taught is how to break large, complex processes into more manageable components. I have experience as an engineer intern within the utility sector working at Consumers Energy, with work focused in root cause analysis and process optimization.

I am entering my fifth year as a member of the Women's Track and Field team at Michigan as a pole vaulter. Within the last year, we have been fortunate enough to win back-to-back Big Ten Conference Titles and I cannot wait for another season with this amazing team! In my somewhat limited free time, I enjoy reading and spending time with friends and family.

I hope the information we've gathered on artificial intelligence and how it is being generated is helpful to the current and future Ross community!

\hypertarget{william-yu}{%
\section{William Yu}\label{william-yu}}

Hello everyone, my name is William Yu and I am from China. I graduated from Indiana University Bloomington in 2022 majoring in Information Systems and Business Analytics. During my undergraduate studies, I had four internships with some consulting and technology firms such as IQVIA and TikTok. I also worked as a research assistant with a professor at the Kelley School of Business, Indiana University, focusing on the impact of dismantling coal power plants on the surrounding environment, economy and housing prices. These experiences game me valuable skills with data analysis helped me pratice my knowledge with some programming and data analysis tools, such as Python, SQL and R. After graduation, I want to find a quantitative analyst position in some financial firms because I want to be at the forefront of leveraging cutting edge quantitative techniques and mathematical models to solve complex financial problems,

During my free time, I am enthusiastic about cycling and triathlon. As a two time Ironman 70.3 finisher, I enjoy pushing myself beyond what I thought possible and the sense of accomplishment after every long-distance endurance workouts.

\hypertarget{aaron-zhao}{%
\section{Aaron Zhao}\label{aaron-zhao}}

Hey there, I'm Aaron! I studied in San Diego, California for my undergraduate degree, and since then, I've taken four epic trips from the West Coast to the East Coast, exploring new places and cultures along the way.

When I'm not studying for my degree, I love working with wood and 3D printing to make cool and useful stuff that brings joy to myself and others. My creative pursuits extend to the kitchen, where I enjoy experimenting to come up with delicious and creative meals. In my free time, I cherish simple pleasures like indulging in cookies and creme ice cream or savoring the delightful sashimi plate.

Psychology has always fascinated me because understanding why people do what they do feels like solving an exciting puzzle.

Alongside my academic and creative passions, I have three adorable and playful chinchillas, which inspire me to craft special things for them to enjoy.

Moreover, sharing knowledge is something I'm truly passionate about. During my undergraduate years, I loved being a teaching assistant, helping others learn and grow. It's an incredibly rewarding experience to see others flourish through my help.

\hypertarget{hardware}{%
\chapter{Hardware}\label{hardware}}

Hardware plays a crucial role in the development of AI Large Language Models (LLMs), as it influences the speed and effectiveness of the model's learning process. Additionally, the nature, size, intricacy, and objective of the model dictate its hardware needs. Key hardware components for AI training include: Processor (CPU) \& Graphic Card (GPU), Memory (RAM) \& Storage (Hard Drives) and Interconnects.

\hypertarget{case-analysis---chatgpt}{%
\section{Case Analysis - ChatGPT}\label{case-analysis---chatgpt}}

ChatGPT has purchased over 10,000 high-quality NVIDIA GPUs, boosting Nvidia product sales to between \$3 billion and \$11 billion annually. Among the GPUs, the NVIDIA A100 HPC \footnote{\url{https://www.nvidia.com/en-us/data-center/a100/}} stands out, priced at \$12,500. It's a top-notch GPU with 80GB of HBM2 memory, providing up to 2TBps memory bandwidth, ideal for running massive models and datasets. However, even with this GPU, there are hurdles in enhancing AI training. For instance, when using PyTorch on a server with multiple GPUs, ChatGPT can only run smaller models like GPT-L due to its complexity and memory fragmentation. As a result, expanding its operation to 4 or 8 GPUs doesn't significantly improve performance. For memory and storage, ChatGPT relies on a mix of technologies such as HBM, SSDs, and Cloud State. Furthermore, it uses PCI Express, NVLink, and Ethernet for connectivity. The estimated daily cost for OpenAI to run these systems is around \$700,000 \footnote{\url{https://finance.yahoo.com/news/chatgpt-cost-bomb-openais-losses-125101043.html}}.

\hypertarget{case-analysis---bard}{%
\section{Case Analysis - Bard}\label{case-analysis---bard}}

In contrast to Bard, another of Google's AI products which uses the GPU provided by NVIDIA, Google employed its own hardware to develop the PaLM model. As of April 2023, Google announced that they had constructed a system consisting of over 4,000 TPUs, complemented by bespoke components engineered specifically for running and training AI models. This system has been operational since 2020 and was the powerhouse behind the training of Google's PaLM model, a rival to OpenAI's GPT, over a span of 50 days. Google researchers have highlighted that their TPU-based supercomputer, dubbed TPUv4, boasts a performance that is between 1.2 to 1.7 times faster and consumes between 1.3 to 1.9 times less energy compared to the Nvidia A100\footnote{\url{https://arxiv.org/abs/2304.01433}}, and this model has cost Google \$100 billion to develop\footnote{\url{https://www.businessinsider.com/how-much-chatgpt-costs-openai-to-run-estimate-report-2023-4?utm_medium=referral\&utm_source=yahoo.com}}.

Image1\footnote{\url{https://epochai.org/blog/trends-in-the-dollar-training-cost-of-machine-learning-systems\#appendix-d-inspecting-the-price-performance-of-nvidia-gpus-as-a-function-of-ml-system-publication-date}}
Image2\footnote{\url{https://medium.com/geekculture/business-analysis-ai-computational-cost-67a136957c95}}

\hypertarget{ethical-dilemma-about-resource-allocation-and-e-waste}{%
\section{Ethical Dilemma about Resource Allocation and E-Waste}\label{ethical-dilemma-about-resource-allocation-and-e-waste}}

The immense computational power needed to train large AI models requires significant financial investment. As we can see in the chart below, the training cost for AI model development has been constantly increasing, and it is predicted to grow exponentially in the following years. The concern arises when considering how these resources might be alternatively used to address pressing societal issues like healthcare, education, infrastructure, or poverty reduction. Also, the allure of cutting-edge AI research may divert talent and funding away from other vital scientific areas. This can create an imbalance in research fields, possibly neglecting areas that might have a more immediate positive impact on human well-being.

image3\footnote{\url{https://digiconomist.net/bitcoin-electronic-waste-monitor/}}

\hypertarget{energy}{%
\chapter{Energy}\label{energy}}

\hypertarget{facts-on-current-generative-ai-energy-usage}{%
\section{Facts on Current Generative AI Energy Usage}\label{facts-on-current-generative-ai-energy-usage}}

\hypertarget{why-training-generative-ai-uses-so-much-energy}{%
\section{Why Training Generative AI Uses So Much Energy}\label{why-training-generative-ai-uses-so-much-energy}}

\hypertarget{how-companies-can-make-ai-models-greener}{%
\section{How Companies Can Make AI Models Greener}\label{how-companies-can-make-ai-models-greener}}

\hypertarget{regulations}{%
\chapter{Regulations}\label{regulations}}

\hypertarget{us-federal-regulations}{%
\section{US Federal Regulations}\label{us-federal-regulations}}

\hypertarget{regulation-abroad}{%
\section{Regulation Abroad}\label{regulation-abroad}}

\hypertarget{challenges-of-regulation}{%
\section{Challenges of Regulation}\label{challenges-of-regulation}}

\hypertarget{benefits-of-regulation}{%
\section{Benefits of Regulation}\label{benefits-of-regulation}}

\hypertarget{censorship}{%
\chapter{Censorship}\label{censorship}}

\hypertarget{pausing-ai-moratorium}{%
\section{``Pausing AI'' / moratorium}\label{pausing-ai-moratorium}}

\hypertarget{internationational-arms-race}{%
\section{Internationational arms race}\label{internationational-arms-race}}

\hypertarget{adapting-to-human-values}{%
\section{Adapting to human values}\label{adapting-to-human-values}}

\hypertarget{data}{%
\chapter{Data}\label{data}}

\hypertarget{diversitybiases-of-data}{%
\section{Diversity/Biases of Data}\label{diversitybiases-of-data}}

\hypertarget{synethic-vs-real-data}{%
\section{Synethic vs Real Data}\label{synethic-vs-real-data}}

\hypertarget{ethical-dilemma-of-web-scraping}{%
\section{Ethical Dilemma of Web Scraping}\label{ethical-dilemma-of-web-scraping}}

\hypertarget{bias}{%
\chapter{Bias}\label{bias}}

\hypertarget{in-llms}{%
\section{In LLMS}\label{in-llms}}

\hypertarget{addressing-the-issue}{%
\section{Addressing the Issue}\label{addressing-the-issue}}

\hypertarget{mit-chatgpt-bias-study}{%
\section{MIT ChatGPT Bias Study}\label{mit-chatgpt-bias-study}}

\hypertarget{alignment}{%
\chapter{Alignment}\label{alignment}}

\hypertarget{what-values-is-ai-supposed-to-align-to}{%
\section{What values is AI supposed to align to?}\label{what-values-is-ai-supposed-to-align-to}}

\hypertarget{how-can-we-generalize-values-despite-coming-from-different-training-data}{%
\section{How can we generalize values despite coming from different training data?}\label{how-can-we-generalize-values-despite-coming-from-different-training-data}}

\hypertarget{long-term-values}{%
\section{Long-term values}\label{long-term-values}}

\hypertarget{algorithmic-improvement}{%
\section{Algorithmic Improvement}\label{algorithmic-improvement}}

\hypertarget{alignment-1}{%
\chapter{Alignment}\label{alignment-1}}

\hypertarget{scaling-laws-for-neural-language-models}{%
\section{Scaling Laws for Neural Language Models}\label{scaling-laws-for-neural-language-models}}

\hypertarget{privacy-enhancing-technologies---mithril-securities-blindai}{%
\section{Privacy Enhancing Technologies - Mithril Securities BlindAI}\label{privacy-enhancing-technologies---mithril-securities-blindai}}

\hypertarget{auto-ml}{%
\section{Auto ML}\label{auto-ml}}

\hypertarget{personalized-large-language-models-llms}{%
\chapter{Personalized Large Language Models (LLMs)}\label{personalized-large-language-models-llms}}

\hypertarget{what-is-hugging-face-and-why-do-we-need-to-know-about-it}{%
\section{What is hugging face, and why do we need to know about it?}\label{what-is-hugging-face-and-why-do-we-need-to-know-about-it}}

\hypertarget{democratizing-access-to-advanced-ai-models}{%
\subsection{Democratizing Access to Advanced AI Models}\label{democratizing-access-to-advanced-ai-models}}

\hypertarget{accelerating-ai-development}{%
\subsection{Accelerating AI Development}\label{accelerating-ai-development}}

\hypertarget{collaboration-and-community}{%
\subsection{Collaboration and Community}\label{collaboration-and-community}}

\hypertarget{open-source-philosophy}{%
\subsection{Open-Source Philosophy}\label{open-source-philosophy}}

\hypertarget{benefits-of-personalized-llms}{%
\section{Benefits of Personalized LLMs}\label{benefits-of-personalized-llms}}

\hypertarget{enhanced-user-experience}{%
\subsection{Enhanced User Experience}\label{enhanced-user-experience}}

\hypertarget{improved-task-performance}{%
\subsection{Improved Task Performance}\label{improved-task-performance}}

\hypertarget{industry-applications}{%
\subsection{Industry Applications}\label{industry-applications}}

\hypertarget{open-source-software-oss-in-ai}{%
\chapter{Open Source Software (OSS) in AI}\label{open-source-software-oss-in-ai}}

\hypertarget{what-is-open-source-software}{%
\section{What is Open Source Software?}\label{what-is-open-source-software}}

\hypertarget{benefits-of-open-source-llms-httpshuggingface.coblogos-llms}{%
\section{\texorpdfstring{Benefits of Open Source LLMs (\url{https://huggingface.co/blog/os-llms})}{Benefits of Open Source LLMs (https://huggingface.co/blog/os-llms)}}\label{benefits-of-open-source-llms-httpshuggingface.coblogos-llms}}

\hypertarget{collaboration-and-innovation}{%
\subsection{Collaboration and Innovation}\label{collaboration-and-innovation}}

\hypertarget{transparency-and-accountability}{%
\subsection{Transparency and Accountability}\label{transparency-and-accountability}}

\hypertarget{collective-advancement}{%
\subsection{Collective Advancement}\label{collective-advancement}}

\hypertarget{examples-of-open-source-projects-for-llms-cut-some-out}{%
\section{Examples of Open-Source Projects for LLMs (Cut some out)}\label{examples-of-open-source-projects-for-llms-cut-some-out}}

\hypertarget{gpt4all}{%
\subsection{GPT4ALL}\label{gpt4all}}

\hypertarget{stability-ai}{%
\subsection{Stability-AI}\label{stability-ai}}

\hypertarget{free-dolly}{%
\subsection{Free Dolly}\label{free-dolly}}

\hypertarget{open-assistant}{%
\subsection{Open Assistant}\label{open-assistant}}

\hypertarget{redpajama}{%
\subsection{RedPajama}\label{redpajama}}

\hypertarget{conclusion---challenges-and-future-directions}{%
\chapter{Conclusion - Challenges and Future Directions}\label{conclusion---challenges-and-future-directions}}

\hypertarget{data-diversity-delete}{%
\section{Data Diversity (delete)}\label{data-diversity-delete}}

\hypertarget{privacy-and-security}{%
\section{Privacy and Security}\label{privacy-and-security}}

\hypertarget{ethical-frameworks}{%
\section{Ethical Frameworks}\label{ethical-frameworks}}

\hypertarget{reference}{%
\chapter{Reference}\label{reference}}

  \bibliography{book.bib,packages.bib}

\end{document}
