<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Privacy | The Ethical Dilemma of Producing Artificial Intelligence (AI)</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Privacy | The Ethical Dilemma of Producing Artificial Intelligence (AI)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Privacy | The Ethical Dilemma of Producing Artificial Intelligence (AI)" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  

<meta name="author" content="Zach Gooding, Nisarg Jhaveri, Catherine Visscher, William Yu, Aaron Zhao" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="alignment.html"/>
<link rel="next" href="personalized-large-language-models-llms.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Insight Titans</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="about-us.html"><a href="about-us.html"><i class="fa fa-check"></i><b>2</b> About Us</a>
<ul>
<li class="chapter" data-level="2.1" data-path="about-us.html"><a href="about-us.html#zach-gooding"><i class="fa fa-check"></i><b>2.1</b> Zach Gooding</a></li>
<li class="chapter" data-level="2.2" data-path="about-us.html"><a href="about-us.html#nisarg-jhaveri"><i class="fa fa-check"></i><b>2.2</b> Nisarg Jhaveri</a></li>
<li class="chapter" data-level="2.3" data-path="about-us.html"><a href="about-us.html#catherine-visscher"><i class="fa fa-check"></i><b>2.3</b> Catherine Visscher</a></li>
<li class="chapter" data-level="2.4" data-path="about-us.html"><a href="about-us.html#william-yu"><i class="fa fa-check"></i><b>2.4</b> William Yu</a></li>
<li class="chapter" data-level="2.5" data-path="about-us.html"><a href="about-us.html#aaron-zhao"><i class="fa fa-check"></i><b>2.5</b> Aaron Zhao</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="hardware.html"><a href="hardware.html"><i class="fa fa-check"></i><b>3</b> Hardware</a>
<ul>
<li class="chapter" data-level="3.1" data-path="hardware.html"><a href="hardware.html#case-analysis---chatgpt"><i class="fa fa-check"></i><b>3.1</b> Case Analysis - ChatGPT</a></li>
<li class="chapter" data-level="3.2" data-path="hardware.html"><a href="hardware.html#case-analysis---bard"><i class="fa fa-check"></i><b>3.2</b> Case Analysis - Bard</a></li>
<li class="chapter" data-level="3.3" data-path="hardware.html"><a href="hardware.html#ethical-dilemmas"><i class="fa fa-check"></i><b>3.3</b> Ethical Dilemmas</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="hardware.html"><a href="hardware.html#resource-allocation"><i class="fa fa-check"></i><b>3.3.1</b> Resource Allocation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html"><i class="fa fa-check"></i><b>4</b> Natural Resource Consumption</a>
<ul>
<li class="chapter" data-level="4.1" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#facts-on-current-generative-ai-energy-usage"><i class="fa fa-check"></i><b>4.1</b> Facts on Current Generative AI Energy Usage</a></li>
<li class="chapter" data-level="4.2" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#why-training-generative-ai-uses-so-much-energy"><i class="fa fa-check"></i><b>4.2</b> Why Training Generative AI Uses So Much Energy</a></li>
<li class="chapter" data-level="4.3" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#ais-water-consumption"><i class="fa fa-check"></i><b>4.3</b> AI’s Water Consumption</a></li>
<li class="chapter" data-level="4.4" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#how-companies-can-make-ai-models-greener"><i class="fa fa-check"></i><b>4.4</b> How Companies Can Make AI Models Greener</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>5</b> Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data.html"><a href="data.html#diversitybiases-of-data"><i class="fa fa-check"></i><b>5.1</b> Diversity/Biases of Data</a></li>
<li class="chapter" data-level="5.2" data-path="data.html"><a href="data.html#web-scraping"><i class="fa fa-check"></i><b>5.2</b> Web Scraping</a></li>
<li class="chapter" data-level="5.3" data-path="data.html"><a href="data.html#intellectual-property"><i class="fa fa-check"></i><b>5.3</b> Intellectual Property</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bias.html"><a href="bias.html"><i class="fa fa-check"></i><b>6</b> Bias</a>
<ul>
<li class="chapter" data-level="6.1" data-path="bias.html"><a href="bias.html#the-subtle-bias-in-training-data"><i class="fa fa-check"></i><b>6.1</b> The Subtle Bias in Training Data</a></li>
<li class="chapter" data-level="6.2" data-path="bias.html"><a href="bias.html#mit-study"><i class="fa fa-check"></i><b>6.2</b> MIT Study</a></li>
<li class="chapter" data-level="6.3" data-path="bias.html"><a href="bias.html#addressing-the-issue"><i class="fa fa-check"></i><b>6.3</b> Addressing The Issue</a></li>
<li class="chapter" data-level="6.4" data-path="bias.html"><a href="bias.html#hallucinations"><i class="fa fa-check"></i><b>6.4</b> Hallucinations</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="alignment.html"><a href="alignment.html"><i class="fa fa-check"></i><b>7</b> Alignment</a>
<ul>
<li class="chapter" data-level="7.1" data-path="alignment.html"><a href="alignment.html#value-alignment"><i class="fa fa-check"></i><b>7.1</b> Value Alignment?</a></li>
<li class="chapter" data-level="7.2" data-path="alignment.html"><a href="alignment.html#generalizing-values"><i class="fa fa-check"></i><b>7.2</b> Generalizing Values</a></li>
<li class="chapter" data-level="7.3" data-path="alignment.html"><a href="alignment.html#drifting"><i class="fa fa-check"></i><b>7.3</b> Drifting</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="alignment.html"><a href="alignment.html#concept-drift5"><i class="fa fa-check"></i><b>7.3.1</b> Concept Drift</a></li>
<li class="chapter" data-level="7.3.2" data-path="alignment.html"><a href="alignment.html#data-drift"><i class="fa fa-check"></i><b>7.3.2</b> Data Drift</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="alignment.html"><a href="alignment.html#algorithmic-improvement"><i class="fa fa-check"></i><b>7.4</b> Algorithmic improvement</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="privacy.html"><a href="privacy.html"><i class="fa fa-check"></i><b>8</b> Privacy</a>
<ul>
<li class="chapter" data-level="8.1" data-path="privacy.html"><a href="privacy.html#scaling-laws-specialized-data-centers-energy-impact"><i class="fa fa-check"></i><b>8.1</b> Scaling Laws &amp; Specialized Data Centers Energy Impact</a></li>
<li class="chapter" data-level="8.2" data-path="privacy.html"><a href="privacy.html#cloud-hosting-privacy-enhancing-technologies"><i class="fa fa-check"></i><b>8.2</b> Cloud Hosting &amp; Privacy Enhancing Technologies</a></li>
<li class="chapter" data-level="8.3" data-path="privacy.html"><a href="privacy.html#automl"><i class="fa fa-check"></i><b>8.3</b> AutoML</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html"><i class="fa fa-check"></i><b>9</b> Personalized Large Language Models (LLMs)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#what-is-hugging-face"><i class="fa fa-check"></i><b>9.1</b> What is Hugging Face?</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#democratizing-access"><i class="fa fa-check"></i><b>9.1.1</b> Democratizing Access</a></li>
<li class="chapter" data-level="9.1.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#accelerating-ai-development-pretrained-models-and-technological-partnerships"><i class="fa fa-check"></i><b>9.1.2</b> Accelerating AI Development: Pretrained Models and Technological Partnerships</a></li>
<li class="chapter" data-level="9.1.3" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#embracing-open-source-principles-for-collective-advancement"><i class="fa fa-check"></i><b>9.1.3</b> Embracing Open-Source Principles for Collective Advancement</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#benefits-of-personalized-llms"><i class="fa fa-check"></i><b>9.2</b> Benefits of Personalized LLMs</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#enhanced-user-experience"><i class="fa fa-check"></i><b>9.2.1</b> Enhanced User Experience</a></li>
<li class="chapter" data-level="9.2.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#improved-task-performance"><i class="fa fa-check"></i><b>9.2.2</b> Improved Task Performance</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#ethical-considerations-challenges"><i class="fa fa-check"></i><b>9.3</b> Ethical Considerations &amp; Challenges</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#bias-and-fairness"><i class="fa fa-check"></i><b>9.3.1</b> Bias and Fairness</a></li>
<li class="chapter" data-level="9.3.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#transparency"><i class="fa fa-check"></i><b>9.3.2</b> Transparency</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html"><i class="fa fa-check"></i><b>10</b> Open-Source Software (OSS) in AI</a>
<ul>
<li class="chapter" data-level="10.1" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#what-is-open-source-software"><i class="fa fa-check"></i><b>10.1</b> What is Open-Source Software?</a></li>
<li class="chapter" data-level="10.2" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#benefits-of-open-source-llms"><i class="fa fa-check"></i><b>10.2</b> Benefits of Open Source LLMs</a></li>
<li class="chapter" data-level="10.3" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#examples-of-open-source-projects-for-llms"><i class="fa fa-check"></i><b>10.3</b> Examples of Open-Source Projects for LLMs</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#gpt4all2"><i class="fa fa-check"></i><b>10.3.1</b> GPT4ALL</a></li>
<li class="chapter" data-level="10.3.2" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#redpajama3"><i class="fa fa-check"></i><b>10.3.2</b> RedPajama</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="conclusion-challenges-and-future-directions.html"><a href="conclusion-challenges-and-future-directions.html"><i class="fa fa-check"></i><b>11</b> Conclusion: Challenges and Future Directions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="conclusion-challenges-and-future-directions.html"><a href="conclusion-challenges-and-future-directions.html#privacy-and-security"><i class="fa fa-check"></i><b>11.1</b> Privacy and Security</a></li>
<li class="chapter" data-level="11.2" data-path="conclusion-challenges-and-future-directions.html"><a href="conclusion-challenges-and-future-directions.html#ethical-frameworks"><i class="fa fa-check"></i><b>11.2</b> Ethical Frameworks</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>12</b> Reference</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Ethical Dilemma of Producing Artificial Intelligence (AI)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="privacy" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Privacy<a href="privacy.html#privacy" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Privacy has been the poster child for problems with LLMs for quite some time now, especially when it comes to the privacy of one’s personal information. There are two main obstacles that stand in the way of true privacy in LLMs: Infrastructure and IP protection. According to Daniel Huynh of Mithril Security, requirements for privacy in infrastructure are “the hosting the model in specialized data centers, e.g., in the Cloud, removes the need for complex infrastructure. It becomes pretty easy to feed data to these models and get a result.” As it relates to IP Protection, Huynh believes that “it becomes much more challenging for AI consumers to steal the model’s weights (notwithstanding model extraction attacks with a black-box API).”<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></p>
<div id="scaling-laws-specialized-data-centers-energy-impact" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Scaling Laws &amp; Specialized Data Centers Energy Impact<a href="privacy.html#scaling-laws-specialized-data-centers-energy-impact" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Mithril Security reflects on a trend discussed in a paper by a team of Computer Scientists at Cornell University called “Scaling Laws for Neural Language Model,” which was published in January of 2020. In this paper, the team is reporting their findings on the study of empirical scaling laws for language model performance on cross-entropy loss. The trend that is discussed is that it seems “the loss scales as a power-law with model size, dataset size, and the amount of compute used for training.”<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a> Daniel Huynh takes this scale of power-law and discusses how “given the power requirements of those models, it also makes sense from an ecological perspective to rely on specialized data centers rather than on-premise deployment.” Furthermore, “economies of scale that Cloud providers leverage are more energy efficient than companies employing on premise.”</p>
<p>Referring back to the first source, this visualization shows how data centers have become increasingly energy efficient. Why Huynh emphasizes this energy efficiency in cloud hosting is because according to the team at Cornell, “simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on the model size.” Basically, cloud hosting is the simplest form of being able to handle the large-scale requirements of LLMs currently.</p>
</div>
<div id="cloud-hosting-privacy-enhancing-technologies" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Cloud Hosting &amp; Privacy Enhancing Technologies<a href="privacy.html#cloud-hosting-privacy-enhancing-technologies" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As it relates back to privacy in LLMs, cloud hosting comes with a cost. According to Mithril Security, “sensitive data becomes potentially exposed to the actors providing those large models and the Cloud Provider.” Unfortunately, given the current processes of these systems, sensitive data being potentially exposed can happen rather easily. “If one actor (either the Cloud or the solution provider) is compromised or malicious, thousands of users’ data can be exposed.” Mithril Security is determined to lead the next steps in LLM production through Privacy Enhancing Technologies. Specifically, Mithril Security has a Privacy Enhancing Technology called BlindAI. BlindAI is “an open-source solution to query and deploy AI models while guaranteeing data privacy. The querying of models is done via our easy-to-use Python library. How it works is “data sent by users to the AI model is kept confidential at all times by hardware-enforced Trusted Execution Environments.” There are two main uses for BlindAI: BlindAI API and BlindAI Core. BlindAI API is “using BlindAI to query popular AI models hosted by Mithril Security.” BlindAI Core is “using BlindAI’s underlying technology to host your own BlindAI server instance to securely deploy your own models.”<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a> The visual below shows BlindAI in practice.</p>
</div>
<div id="automl" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> AutoML<a href="privacy.html#automl" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another current process for privacy in LLMs is AutoML. “AutoML refers to the automated process of end-to-end development of machine learning models. It involves automating data preprocessing, feature selection, model selection, and hyperparameter tuning. It allows users with varying levels of expertise to develop machine-learning models with high efficiency and minimal manual intervention.” There are several reasons to employ AutoML. First and foremost, “organizations can maintain full control of their data.” Obviously, keeping sensitive information in-house limits the transferring of information, thus reducing the chance it is exposed. According to Manuel Herranz, the CEO of Pangeanic, “this approach ensures data privacy regulations compliance, a crucial aspect in sectors like healthcare, finance, and education, where stringent data privacy rules apply.” Furthermore, self-training LLMs like AutoML “reduces the dependency on external tech giants, providing more autonomy to organizations.<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> BlindAI and AutoML are two different ways to increase privacy in the production of LLMs.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="33">
<li id="fn33"><p><a href="https://privacytools.seas.harvard.edu/differential-privacy" class="uri">https://privacytools.seas.harvard.edu/differential-privacy</a><a href="privacy.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p><a href="https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community" class="uri">https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community</a><a href="privacy.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p><a href="https://venturebeat.com/ai/redpajama-replicates-llama-to-build-open-source-state-of-the-art-llms/" class="uri">https://venturebeat.com/ai/redpajama-replicates-llama-to-build-open-source-state-of-the-art-llms/</a><a href="privacy.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p><a href="https://huggingface.co/docs/transformers/philosophy" class="uri">https://huggingface.co/docs/transformers/philosophy</a><a href="privacy.html#fnref36" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="alignment.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="personalized-large-language-models-llms.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/08-Privacy.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["my-book.pdf", "my-book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
