<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Alignment | The Ethical Dilemma of Producing Artificial Intelligence (AI)</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Alignment | The Ethical Dilemma of Producing Artificial Intelligence (AI)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Alignment | The Ethical Dilemma of Producing Artificial Intelligence (AI)" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  

<meta name="author" content="Zach Gooding, Nisarg Jhaveri, Catherine Visscher, William Yu, Aaron Zhao" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bias.html"/>
<link rel="next" href="privacy.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Insight Titans</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="about-us.html"><a href="about-us.html"><i class="fa fa-check"></i><b>2</b> About Us</a>
<ul>
<li class="chapter" data-level="2.1" data-path="about-us.html"><a href="about-us.html#zach-gooding"><i class="fa fa-check"></i><b>2.1</b> Zach Gooding</a></li>
<li class="chapter" data-level="2.2" data-path="about-us.html"><a href="about-us.html#nisarg-jhaveri"><i class="fa fa-check"></i><b>2.2</b> Nisarg Jhaveri</a></li>
<li class="chapter" data-level="2.3" data-path="about-us.html"><a href="about-us.html#catherine-visscher"><i class="fa fa-check"></i><b>2.3</b> Catherine Visscher</a></li>
<li class="chapter" data-level="2.4" data-path="about-us.html"><a href="about-us.html#william-yu"><i class="fa fa-check"></i><b>2.4</b> William Yu</a></li>
<li class="chapter" data-level="2.5" data-path="about-us.html"><a href="about-us.html#aaron-zhao"><i class="fa fa-check"></i><b>2.5</b> Aaron Zhao</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="hardware.html"><a href="hardware.html"><i class="fa fa-check"></i><b>3</b> Hardware</a>
<ul>
<li class="chapter" data-level="3.1" data-path="hardware.html"><a href="hardware.html#case-analysis---chatgpt"><i class="fa fa-check"></i><b>3.1</b> Case Analysis - ChatGPT</a></li>
<li class="chapter" data-level="3.2" data-path="hardware.html"><a href="hardware.html#case-analysis---bard"><i class="fa fa-check"></i><b>3.2</b> Case Analysis - Bard</a></li>
<li class="chapter" data-level="3.3" data-path="hardware.html"><a href="hardware.html#ethical-dilemmas-in-resource-allocation-and-e-waste"><i class="fa fa-check"></i><b>3.3</b> Ethical Dilemmas in Resource Allocation and E-Waste</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html"><i class="fa fa-check"></i><b>4</b> Natural Resource Consumption</a>
<ul>
<li class="chapter" data-level="4.1" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#facts-on-current-generative-ai-energy-usage"><i class="fa fa-check"></i><b>4.1</b> Facts on Current Generative AI Energy Usage</a></li>
<li class="chapter" data-level="4.2" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#why-training-generative-ai-uses-so-much-energy"><i class="fa fa-check"></i><b>4.2</b> Why Training Generative AI Uses So Much Energy</a></li>
<li class="chapter" data-level="4.3" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#ais-water-consumption"><i class="fa fa-check"></i><b>4.3</b> AI’s Water Consumption</a></li>
<li class="chapter" data-level="4.4" data-path="natural-resource-consumption.html"><a href="natural-resource-consumption.html#how-companies-can-make-ai-models-greener"><i class="fa fa-check"></i><b>4.4</b> How Companies Can Make AI Models Greener</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>5</b> Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data.html"><a href="data.html#diversitybiases-of-data"><i class="fa fa-check"></i><b>5.1</b> Diversity/Biases of Data</a></li>
<li class="chapter" data-level="5.2" data-path="data.html"><a href="data.html#web-scraping"><i class="fa fa-check"></i><b>5.2</b> Web Scraping</a></li>
<li class="chapter" data-level="5.3" data-path="data.html"><a href="data.html#intellectual-property"><i class="fa fa-check"></i><b>5.3</b> Intellectual Property</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bias.html"><a href="bias.html"><i class="fa fa-check"></i><b>6</b> Bias</a>
<ul>
<li class="chapter" data-level="6.1" data-path="bias.html"><a href="bias.html#the-subtle-bias-in-training-data"><i class="fa fa-check"></i><b>6.1</b> The Subtle Bias in Training Data</a></li>
<li class="chapter" data-level="6.2" data-path="bias.html"><a href="bias.html#mit-study"><i class="fa fa-check"></i><b>6.2</b> MIT Study</a></li>
<li class="chapter" data-level="6.3" data-path="bias.html"><a href="bias.html#addressing-the-issue"><i class="fa fa-check"></i><b>6.3</b> Addressing The Issue</a></li>
<li class="chapter" data-level="6.4" data-path="bias.html"><a href="bias.html#hallucinations"><i class="fa fa-check"></i><b>6.4</b> Hallucinations</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="alignment.html"><a href="alignment.html"><i class="fa fa-check"></i><b>7</b> Alignment</a>
<ul>
<li class="chapter" data-level="7.1" data-path="alignment.html"><a href="alignment.html#value-alignment"><i class="fa fa-check"></i><b>7.1</b> Value Alignment?</a></li>
<li class="chapter" data-level="7.2" data-path="alignment.html"><a href="alignment.html#generalizing-values"><i class="fa fa-check"></i><b>7.2</b> Generalizing Values</a></li>
<li class="chapter" data-level="7.3" data-path="alignment.html"><a href="alignment.html#drifting"><i class="fa fa-check"></i><b>7.3</b> Drifting</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="alignment.html"><a href="alignment.html#concept-drift5"><i class="fa fa-check"></i><b>7.3.1</b> Concept Drift</a></li>
<li class="chapter" data-level="7.3.2" data-path="alignment.html"><a href="alignment.html#data-drift"><i class="fa fa-check"></i><b>7.3.2</b> Data Drift</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="alignment.html"><a href="alignment.html#algorithmic-improvement"><i class="fa fa-check"></i><b>7.4</b> Algorithmic improvement</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="privacy.html"><a href="privacy.html"><i class="fa fa-check"></i><b>8</b> Privacy</a>
<ul>
<li class="chapter" data-level="8.1" data-path="privacy.html"><a href="privacy.html#scaling-laws-specialized-data-centers-energy-impact"><i class="fa fa-check"></i><b>8.1</b> Scaling Laws &amp; Specialized Data Centers Energy Impact</a></li>
<li class="chapter" data-level="8.2" data-path="privacy.html"><a href="privacy.html#cloud-hosting-privacy-enhancing-technologies"><i class="fa fa-check"></i><b>8.2</b> Cloud Hosting &amp; Privacy Enhancing Technologies</a></li>
<li class="chapter" data-level="8.3" data-path="privacy.html"><a href="privacy.html#automl"><i class="fa fa-check"></i><b>8.3</b> AutoML</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html"><i class="fa fa-check"></i><b>9</b> Personalized Large Language Models (LLMs)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#what-is-hugging-face"><i class="fa fa-check"></i><b>9.1</b> What is Hugging Face?</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#democratizing-access"><i class="fa fa-check"></i><b>9.1.1</b> Democratizing Access</a></li>
<li class="chapter" data-level="9.1.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#accelerating-ai-development-pretrained-models-and-technological-partnerships"><i class="fa fa-check"></i><b>9.1.2</b> Accelerating AI Development: Pretrained Models and Technological Partnerships</a></li>
<li class="chapter" data-level="9.1.3" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#embracing-open-source-principles-for-collective-advancement"><i class="fa fa-check"></i><b>9.1.3</b> Embracing Open-Source Principles for Collective Advancement</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#benefits-of-personalized-llms"><i class="fa fa-check"></i><b>9.2</b> Benefits of Personalized LLMs</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#enhanced-user-experience"><i class="fa fa-check"></i><b>9.2.1</b> Enhanced User Experience</a></li>
<li class="chapter" data-level="9.2.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#improved-task-performance"><i class="fa fa-check"></i><b>9.2.2</b> Improved Task Performance</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#ethical-considerations-challenges"><i class="fa fa-check"></i><b>9.3</b> Ethical Considerations &amp; Challenges</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#bias-and-fairness"><i class="fa fa-check"></i><b>9.3.1</b> Bias and Fairness</a></li>
<li class="chapter" data-level="9.3.2" data-path="personalized-large-language-models-llms.html"><a href="personalized-large-language-models-llms.html#transparency"><i class="fa fa-check"></i><b>9.3.2</b> Transparency</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html"><i class="fa fa-check"></i><b>10</b> Open-Source Software (OSS) in AI</a>
<ul>
<li class="chapter" data-level="10.1" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#what-is-open-source-software"><i class="fa fa-check"></i><b>10.1</b> What is Open-Source Software?</a></li>
<li class="chapter" data-level="10.2" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#benefits-of-open-source-llms"><i class="fa fa-check"></i><b>10.2</b> Benefits of Open Source LLMs</a></li>
<li class="chapter" data-level="10.3" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#examples-of-open-source-projects-for-llms"><i class="fa fa-check"></i><b>10.3</b> Examples of Open-Source Projects for LLMs</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#gpt4all2"><i class="fa fa-check"></i><b>10.3.1</b> GPT4ALL</a></li>
<li class="chapter" data-level="10.3.2" data-path="open-source-software-oss-in-ai.html"><a href="open-source-software-oss-in-ai.html#redpajama3"><i class="fa fa-check"></i><b>10.3.2</b> RedPajama</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="conclusion-challenges-and-future-directions.html"><a href="conclusion-challenges-and-future-directions.html"><i class="fa fa-check"></i><b>11</b> Conclusion: Challenges and Future Directions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="conclusion-challenges-and-future-directions.html"><a href="conclusion-challenges-and-future-directions.html#privacy-and-security"><i class="fa fa-check"></i><b>11.1</b> Privacy and Security</a></li>
<li class="chapter" data-level="11.2" data-path="conclusion-challenges-and-future-directions.html"><a href="conclusion-challenges-and-future-directions.html#ethical-frameworks"><i class="fa fa-check"></i><b>11.2</b> Ethical Frameworks</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>12</b> Reference</a></li>
<li class="chapter" data-level="13" data-path="how-we-build-our-book.html"><a href="how-we-build-our-book.html"><i class="fa fa-check"></i><b>13</b> How We Build Our Book</a>
<ul>
<li class="chapter" data-level="13.1" data-path="how-we-build-our-book.html"><a href="how-we-build-our-book.html#documentation-of-our-group-process"><i class="fa fa-check"></i><b>13.1</b> Documentation of Our Group Process</a></li>
<li class="chapter" data-level="13.2" data-path="how-we-build-our-book.html"><a href="how-we-build-our-book.html#how-did-our-group-handle-challenges-and-change"><i class="fa fa-check"></i><b>13.2</b> How Did Our Group Handle Challenges and Change</a></li>
<li class="chapter" data-level="13.3" data-path="how-we-build-our-book.html"><a href="how-we-build-our-book.html#how-did-we-divide-work-and-leverage-unique-strengths-of-each-team-member"><i class="fa fa-check"></i><b>13.3</b> How Did We Divide Work and Leverage Unique Strengths of Each Team Member?</a></li>
<li class="chapter" data-level="13.4" data-path="how-we-build-our-book.html"><a href="how-we-build-our-book.html#how-did-we-adopt-agile-work-practices"><i class="fa fa-check"></i><b>13.4</b> How Did We Adopt Agile Work Practices</a></li>
<li class="chapter" data-level="13.5" data-path="how-we-build-our-book.html"><a href="how-we-build-our-book.html#concluding-thoughts-as-a-team"><i class="fa fa-check"></i><b>13.5</b> Concluding Thoughts as a Team</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Ethical Dilemma of Producing Artificial Intelligence (AI)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="alignment" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Alignment<a href="alignment.html#alignment" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>By its very definition, we are seeking to have AI understand and remain in line with human interests as the systems become more capable and autonomous. Working with limited sets of data, the alignment becomes particularly important as we need to prevent unintended negative consequences or risks. Human values, as previously mentioned, are ever-evolving and can have various interpretations for any given scenario based on the context of a particular culture. This brings us to our list of issues with alignment: what is the desired specification of human value? Can AI learn and generalize values based on a training dataset that may be different? Can we have AI stick to the values for the longer-term/not drift away from human-centric values? And lastly, can algorithms improve over time?</p>
<div id="value-alignment" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Value Alignment?<a href="alignment.html#value-alignment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What values are AI supposed to align with? We can consider two schools of thought here, one where we take a single user and ensure that the model is aligned with their perspective, i.e., self-driving or autonomous vehicles where there is only one driver and we want to make sure that the vehicle is only listening to commands from the user and doesn’t do its own thing. The other perspective is more along the lines of a global alignment with the entire human race so we do not have a catastrophic event occur or create risks on that level. However, most cases tend to fall under the gray area between the two where we have multiple people with diverse groups of users and thus subsets of humanity in general. This essentially ends up creating overlapping values but conflicting interests. With diverse groups, we have yet another loop of issues, are all values considered equal, or do you train your LLM to value one over the other?</p>
<p>With the emergence of these questions, one would normally expect the AI system to mimic and align itself in a manner of current human societies and follow a complex hierarchy based on status, power, wealth, and influence which would seem improbable, not to mention highly unethical - essentially bringing us back to square one. A suggestive approach might be to implement a general cooperative inverse reinforcement learning model where certain responses are punished and removed from the model. However, the conflict of interests would soon make the CIRL model inefficient or ineffective as it slowly complicates itself.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
</div>
<div id="generalizing-values" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Generalizing Values<a href="alignment.html#generalizing-values" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Imagine a scatter plot, one of the most basic ones with a linear progression displaying a certain slope on the chart. Then add a trendline to get the m from our basic y = mx + b equation. That trendline that was created is the equivalent of generalization in machine learning, as no matter where you try to place the line, you will still have points that are away from the trendline you have created.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></p>
<p>Let’s say you create a very complex model that takes into account all the data points on the chart. Now, we have a complicated system that is not only slower but also has one fatal flaw which would be its vulnerability to new data sets.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<p>Ideally speaking, you want the model to be as simple as possible and then have the system predict a new sample of data, compare the new sample, and improve based on the differences. The basic assumptions are that the examples are independent and identical, the distribution is stationary - meaning the data doesn’t change over time, and whenever the data is pulled, it is the same distribution for training, validation, and test sets.</p>
<p>As we would have already assumed, the assumptions are straightforward to break, especially with the stationary assumption, as user input is very inconsistent and can change over time. For instance, an online shopper might change their preferences as the seasons change or new things come into fashion.
To conclude on the biggest nightmare of data scientists across the globe: overfitting, incomplete data, and inaccurate data labels make it nigh impossible for the models to adapt to new data. Overfitting means that the parameters of the model are too specific to the current dataset, and inaccurate data labels cause difficulties in supervised learning while training AI models.</p>
</div>
<div id="drifting" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Drifting<a href="alignment.html#drifting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s say we train this amazingly complex system that is in line with our expectations of generalized human values and can adapt to new data despite having a limited training dataset; the next step would be to ensure that the model doesn’t “drift.” So what does drift mean? Drift is a term used to describe how a machine learning model’s performance tends to get worse over time as the models lose their accuracy due to changes in the environment. The changes can happen as the training dataset is simply outdated, the model is being applied to a new context, or the desired output keeps changing with a wide distribution of input.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a></p>
<p>As one can imagine, this can be a big problem as the real world keeps changing and we can experience various types of drifts as the model tries to adapt to the changing environment and depending on the model’s ability to handle new data we can notice different types of drifts.</p>
<div id="concept-drift5" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Concept Drift<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a><a href="alignment.html#concept-drift5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure">
<img src="figures/figure6.png" alt="" />
<p class="caption">An Example of Concept Drift Types</p>
</div>
<p>The following explanations for various types of drift have been provided by ChatGPT:<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a></p>
<ul>
<li><p>Sudden Drift: Sudden concept drift occurs when the underlying task experiences a rapid change. An example could be a sentiment analysis model that was trained on a corpus of online reviews. If a new trend or event significantly alters the language used in reviews, the model’s effectiveness might diminish abruptly.</p></li>
<li><p>Gradual Drift: Gradual concept drift involves a slow shift in the underlying task. For instance, a weather forecasting model might face gradual drift as climate patterns evolve over time, requiring the model to adapt its predictions.</p></li>
<li><p>Incremental Drift: Incremental drift refers to gradual changes that accumulate over time, causing the
model’s performance to gradually decline. This type of drift is often encountered in scenarios where the task involves dynamic and evolving data.</p></li>
<li><p>Recurring Concepts: Recurring concept drift happens when patterns in the data repeat themselves periodically. In finance, for instance, economic cycles can cause models to experience recurring concept drift.</p></li>
</ul>
</div>
<div id="data-drift" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Data Drift<a href="alignment.html#data-drift" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Data drift, also known as covariate shift, focuses on changes in the distribution of input data. This type of drift can impact a model’s accuracy even when the task remains constant. An example would be a medical diagnosis model trained on data from a specific hospital. If the demographics of the patients change over time, the model might struggle to make accurate diagnoses.</p>
<p>With systems designed and in place for the detection of any form of drifting, we can quickly and efficiently reinforce our models to provide desired outputs for these commonly occurring drifts.</p>
</div>
</div>
<div id="algorithmic-improvement" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Algorithmic improvement<a href="alignment.html#algorithmic-improvement" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Self-improving AI is a concept that is not foreign to those who have been in the field for a while. Our current AI systems are limited and narrow; however, the long-term goal has always been aimed at creating a system of artificial general intelligence - AGI.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a></p>
<p>AGI systems can be a potential solution to this problem, as noted by Ramana Kumar, an AGI safety researcher at DeepMind, as this self-improvement capability would be an innate characteristic of AGI. So despite being a theoretically sound thing, what is stopping the creation of AGI? It is a matter of scaling.
We require the existing machine-learning models to be scaled up, for instance, with faster hardware. We can have incremental research progress for different forms of learning, such as representation, transfer, and model-based reinforcement. This form of recursive self-improvement allows the system to establish a feedback loop for making adjustments to its own functionality to improve performance.<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="25">
<li id="fn25"><p><a href="https://privacytools.seas.harvard.edu/differential-privacy" class="uri">https://privacytools.seas.harvard.edu/differential-privacy</a><a href="alignment.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p><a href="https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community" class="uri">https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community</a><a href="alignment.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p><a href="https://venturebeat.com/ai/redpajama-replicates-llama-to-build-open-source-state-of-the-art-llms/" class="uri">https://venturebeat.com/ai/redpajama-replicates-llama-to-build-open-source-state-of-the-art-llms/</a><a href="alignment.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p><a href="https://huggingface.co/docs/transformers/philosophy" class="uri">https://huggingface.co/docs/transformers/philosophy</a><a href="alignment.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p><a href="https://research.netflix.com/research-area/machine-learning" class="uri">https://research.netflix.com/research-area/machine-learning</a><a href="alignment.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p><a href="https://www.nature.com/articles/s41591-023-02448-8" class="uri">https://www.nature.com/articles/s41591-023-02448-8</a><a href="alignment.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p><a href="https://www.cancer.gov/news-events/cancer-currents-blog/2022/artificial-intelligence-cancer-imaging" class="uri">https://www.cancer.gov/news-events/cancer-currents-blog/2022/artificial-intelligence-cancer-imaging</a><a href="alignment.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p><a href="https://news.umich.edu/new-language-learning-algorithms-risk-reinforcing-inequalities-social-fragmentation-per-u-m-study/" class="uri">https://news.umich.edu/new-language-learning-algorithms-risk-reinforcing-inequalities-social-fragmentation-per-u-m-study/</a><a href="alignment.html#fnref32" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bias.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="privacy.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/07-Alignment.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["my-book.pdf", "my-book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
